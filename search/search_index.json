{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LLVM-VE Vector Intrinsics Tutorial LLVM-VE supports intrinsic functions for vector instructions of SX-Aurora TSUBASA's Vector Engine. In this document, we call it \"VE instrinsics\" or just \"intrinsics\". Complete list of VE instrinsics can be found here . This document includes following sections. Introduction: Implementing VectorAdd Getting Started: Setting up LLVM-VE Basics of VE Intrinsics Other Topics Optimization Hints References","title":"Home"},{"location":"#llvm-ve-vector-intrinsics-tutorial","text":"LLVM-VE supports intrinsic functions for vector instructions of SX-Aurora TSUBASA's Vector Engine. In this document, we call it \"VE instrinsics\" or just \"intrinsics\". Complete list of VE instrinsics can be found here . This document includes following sections. Introduction: Implementing VectorAdd Getting Started: Setting up LLVM-VE Basics of VE Intrinsics Other Topics Optimization Hints References","title":"LLVM-VE Vector Intrinsics Tutorial"},{"location":"basics/","text":"Basics of VE Intrinsics This section describes some basic consepts of VE Intrinsics. Design of VE Intrinsics VE intrinsics are intended to be as consistent as possible with the VE assembly described in the assembly manual . Conventions such as function name, order of arguments are borrowed from the assembly. This is because goal of VE intrinsics is providing an easy way to write assembly code with help of the compiler techniques such as register allocation, transformations like unrolling and C++ template. If you are familiar with VE ISA, you can start to write intrinsics without reading this document, function list is all you need. But this section helps to understand VE intrinsics quickly. Knowledge on other vector ISA or SIMD ISA could help to understand VE intrinsics. Unfortunately the assembly manual does not describe functionality of instructions. You may need to refer the ISA guide to know what intrinsics do. Our intrinsic list includes links to both manuals. Vector Type and Functions VE Intrinsics introduce vector type __vr and functions that operate on __vr type variables. Typical code with intrinsics starts with loading data into __vr type variables, then works with them, and finally stores to memory. Vector Type __vr is defined as below. It can hold 256 x 64bit values (2048KB in total). typedef double __vr __attribute__((__vector_size__(2048))); Variables of __vr are assigned to vector registers. As a vector register can hold any types of value including fp32, fp64, int32, int64, etc, you can place any types of value into __vr variable. It is important to know that VE has 64 vector registers. Using too many __vr variables results in vector register spills you all hate. Intrinsic Functions Function format is _vel_<asm>_<suffix> . <asm> is an instruction mnemonic in the assembly manual . Some assembly instructions have mnemonic suffix to give additional means to an instruction. For example, vfadd.d instruction has .d suffix to show that operands are handled as fp64. See the assembly manual for the complete list of mnemonic suffix. In intrinsics, dot( . ) in mnemonic is simply removed. For example, vfadd.d becomes vfaddd . <suffix> is a list of types of return value and arguments in a single character. v : vector s : scalar m and M : vector mask for 256 elements and 512 elements l : vector length For example, suffix vssl in _vel_vld_vssl means vector(return value), scalar(1st argument), scalar(2nd) and vector length(3rd). Some functions has variants with different suffix to accept different type of arguments. For example, _vel_vfaddd_vvvl is addition of two vectors and _vel_vfaddd_vsvl is addition among a vector and a scalar where a scalar is added to all elements in a vector. Vector Length and Pass Through Argument Vector length argument shows number of elements updated by the function. For example, va = _vel_vfaddd_vvvl(vb, vc, 100) updates first 100 elements of va with the result of vb + vc . Elements after vector length, i.e. last 156 elements in this case, becomes undefined . Note that this is different from hardware instructions where such elements are not changed. You can use another variant of a function to give a pass through argument that is filled into elements after vector length. For example, _vel_vfaddd_vvvvl (four v s in a suffix) is the variant of _vel_vfaddd_vvvl (three v s) and its third argument is a pass through argument (In the intrinsics list , a pass through argument is shown as pt ). In the case of va = _vel_vfaddd_vvvvl(vb, vc, vd, 100) , last 156 elements of va are updated with last 156 elements of vd . Typically, a pass through argument is same as an output variable like va = _vel_vfadd_vvvvl(vb, vc, va, 100) to keep elements after vector length unchanged. Note: Hardware vector instructions do not actually have a vector length operand. Instead vector length is given by the vector length register, and its value is loaded by LVL (Load Vector Length) instruction. VE intrinsics does not provide a function for LVL instruction, but it is automatically generated by the compiler from a vector length argument in intrinsics. Vector Mask VE has eight 256 bit vector mask registers. A vector mask register is given to a vector instruction to mask elements of its output vector. When an element is masked, i.e. a bit is zero, such element is not updated by the instruction. VE intrinsics introduce __vm256 type to hold a vector mask. Intrinsic functions has variants that accept __vm256 variable as an argument. Such variants also accept a pass through argument to fill masked elements. For example, the variant of _vel_vfaddd_vvvl is _vel_vfaddd_vvvmvl where m in suffix shows a vector mask and v after m means a pass through argument. va = _vel_vfaddd_vvvmvl(vb, vc, vm, vd, vl) works as for (i = 0; i < vl; ++i) va[i] = vm[i] ? vb[i] + vc[i] : vd[i] Typically, a pass through argument is same as an output variable like va = _vel_vfadd_vvvmvl(vb, vc, vm, va, vl) to keep masked elements unchanged. A vector mask is used for a loop with a conditional branch. void vaddif(double* a, double const* b, double const* c, double const* cond, int n) { for (int i = 0; i < n; ++i) { if (cond[i] > 0.0) a[i] = b[i] + c[i]; } } An example written in intrinsics is shown below. #define VL 256 for (int i = 0; i < n; i += VL) { int vl = std::min(VL, n - i); __vr va = _vel_vld_vssl(8, a, vl); __vr vb = _vel_vld_vssl(8, b, vl); __vr vc = _vel_vld_vssl(8, c, vl); __vr vcond = _vel_vld_vssl(8, cond, vl); __vm256 mask = _vel_vfmkdgt_mvl(vcond, vl); // mask = vcond > 0 va = _vel_vfaddd_vvvmvl(vb, vc, mask, va, vl); // va = mask ? vb + vc : va _vel_vst_vssl(va, 8, a, vl); a += vl; b += vl; c += vl; cond += vl; }","title":"Basics of VE Intrinsiss"},{"location":"basics/#basics-of-ve-intrinsics","text":"This section describes some basic consepts of VE Intrinsics.","title":"Basics of VE Intrinsics"},{"location":"basics/#design-of-ve-intrinsics","text":"VE intrinsics are intended to be as consistent as possible with the VE assembly described in the assembly manual . Conventions such as function name, order of arguments are borrowed from the assembly. This is because goal of VE intrinsics is providing an easy way to write assembly code with help of the compiler techniques such as register allocation, transformations like unrolling and C++ template. If you are familiar with VE ISA, you can start to write intrinsics without reading this document, function list is all you need. But this section helps to understand VE intrinsics quickly. Knowledge on other vector ISA or SIMD ISA could help to understand VE intrinsics. Unfortunately the assembly manual does not describe functionality of instructions. You may need to refer the ISA guide to know what intrinsics do. Our intrinsic list includes links to both manuals.","title":"Design of VE Intrinsics"},{"location":"basics/#vector-type-and-functions","text":"VE Intrinsics introduce vector type __vr and functions that operate on __vr type variables. Typical code with intrinsics starts with loading data into __vr type variables, then works with them, and finally stores to memory.","title":"Vector Type and Functions"},{"location":"basics/#vector-type","text":"__vr is defined as below. It can hold 256 x 64bit values (2048KB in total). typedef double __vr __attribute__((__vector_size__(2048))); Variables of __vr are assigned to vector registers. As a vector register can hold any types of value including fp32, fp64, int32, int64, etc, you can place any types of value into __vr variable. It is important to know that VE has 64 vector registers. Using too many __vr variables results in vector register spills you all hate.","title":"Vector Type"},{"location":"basics/#intrinsic-functions","text":"Function format is _vel_<asm>_<suffix> . <asm> is an instruction mnemonic in the assembly manual . Some assembly instructions have mnemonic suffix to give additional means to an instruction. For example, vfadd.d instruction has .d suffix to show that operands are handled as fp64. See the assembly manual for the complete list of mnemonic suffix. In intrinsics, dot( . ) in mnemonic is simply removed. For example, vfadd.d becomes vfaddd . <suffix> is a list of types of return value and arguments in a single character. v : vector s : scalar m and M : vector mask for 256 elements and 512 elements l : vector length For example, suffix vssl in _vel_vld_vssl means vector(return value), scalar(1st argument), scalar(2nd) and vector length(3rd). Some functions has variants with different suffix to accept different type of arguments. For example, _vel_vfaddd_vvvl is addition of two vectors and _vel_vfaddd_vsvl is addition among a vector and a scalar where a scalar is added to all elements in a vector.","title":"Intrinsic Functions"},{"location":"basics/#vector-length-and-pass-through-argument","text":"Vector length argument shows number of elements updated by the function. For example, va = _vel_vfaddd_vvvl(vb, vc, 100) updates first 100 elements of va with the result of vb + vc . Elements after vector length, i.e. last 156 elements in this case, becomes undefined . Note that this is different from hardware instructions where such elements are not changed. You can use another variant of a function to give a pass through argument that is filled into elements after vector length. For example, _vel_vfaddd_vvvvl (four v s in a suffix) is the variant of _vel_vfaddd_vvvl (three v s) and its third argument is a pass through argument (In the intrinsics list , a pass through argument is shown as pt ). In the case of va = _vel_vfaddd_vvvvl(vb, vc, vd, 100) , last 156 elements of va are updated with last 156 elements of vd . Typically, a pass through argument is same as an output variable like va = _vel_vfadd_vvvvl(vb, vc, va, 100) to keep elements after vector length unchanged. Note: Hardware vector instructions do not actually have a vector length operand. Instead vector length is given by the vector length register, and its value is loaded by LVL (Load Vector Length) instruction. VE intrinsics does not provide a function for LVL instruction, but it is automatically generated by the compiler from a vector length argument in intrinsics.","title":"Vector Length and Pass Through Argument"},{"location":"basics/#vector-mask","text":"VE has eight 256 bit vector mask registers. A vector mask register is given to a vector instruction to mask elements of its output vector. When an element is masked, i.e. a bit is zero, such element is not updated by the instruction. VE intrinsics introduce __vm256 type to hold a vector mask. Intrinsic functions has variants that accept __vm256 variable as an argument. Such variants also accept a pass through argument to fill masked elements. For example, the variant of _vel_vfaddd_vvvl is _vel_vfaddd_vvvmvl where m in suffix shows a vector mask and v after m means a pass through argument. va = _vel_vfaddd_vvvmvl(vb, vc, vm, vd, vl) works as for (i = 0; i < vl; ++i) va[i] = vm[i] ? vb[i] + vc[i] : vd[i] Typically, a pass through argument is same as an output variable like va = _vel_vfadd_vvvmvl(vb, vc, vm, va, vl) to keep masked elements unchanged. A vector mask is used for a loop with a conditional branch. void vaddif(double* a, double const* b, double const* c, double const* cond, int n) { for (int i = 0; i < n; ++i) { if (cond[i] > 0.0) a[i] = b[i] + c[i]; } } An example written in intrinsics is shown below. #define VL 256 for (int i = 0; i < n; i += VL) { int vl = std::min(VL, n - i); __vr va = _vel_vld_vssl(8, a, vl); __vr vb = _vel_vld_vssl(8, b, vl); __vr vc = _vel_vld_vssl(8, c, vl); __vr vcond = _vel_vld_vssl(8, cond, vl); __vm256 mask = _vel_vfmkdgt_mvl(vcond, vl); // mask = vcond > 0 va = _vel_vfaddd_vvvmvl(vb, vc, mask, va, vl); // va = mask ? vb + vc : va _vel_vst_vssl(va, 8, a, vl); a += vl; b += vl; c += vl; cond += vl; }","title":"Vector Mask"},{"location":"intro/","text":"Introduction: Implementing VectorAdd Let's start with a simple example. This is C/C++ implementation of addition of two vectors. void vadd(double* a, double const* b, double const* c, int n) { for (int i = 0; i < n; ++i) a[i] = b[i] + c[i]; } Vector instructions can operate 256 elements in a single instruction. Strip-mining to make an innermost loop with 256 iterations is first step to use intrinsics. #define VL 256 void vadd(double* a, double const* b, double const* c, int n) { for (int i = 0; i < n; i += VL) { int vl = min(VL, n - i); for (int j = 0; j < vl; ++j) a[j] = b[j] + c[j]; a += vl; b += vl; c += vl; } } Then replace the innermost loop with intrinsic functions and __vr (vector register) type variables after including velintrin.h . #include <velintrin.h> #define VL 256 void vadd(double* a, double const* b, double const* c, int n) { for (int i = 0; i < n; i += VL) { int vl = min(VL, n - i); __vr vb = _vel_vld_vssl(8, b, vl); // load b to vb __vr vc = _vel_vld_vssl(8, c, vl); // load c to vc __vr va = _vel_vfaddd_vvvl(vb, bc, vl); // va = vb + vc _vel_vst_vssl(va, 8, a, vl); // store va to a a += vl; b += vl; c += vl; } } A vector register can hold 256 64bit elements and an intrinsic function operates vl elements in it. vl is passed as a last argument of an intrinsic function. The four intrinsics used in this example are compiled to four vector instructions vld, vld, vfadd.d, vst . This is an important benefit of intrinsics. You can use the instructions you want to use. Other examples can be found: https://github.com/sx-aurora-dev/vetfkernel/tree/master/vml/src/intrinsic https://github.com/sx-aurora-dev/vednn","title":"Introduction"},{"location":"intro/#introduction-implementing-vectoradd","text":"Let's start with a simple example. This is C/C++ implementation of addition of two vectors. void vadd(double* a, double const* b, double const* c, int n) { for (int i = 0; i < n; ++i) a[i] = b[i] + c[i]; } Vector instructions can operate 256 elements in a single instruction. Strip-mining to make an innermost loop with 256 iterations is first step to use intrinsics. #define VL 256 void vadd(double* a, double const* b, double const* c, int n) { for (int i = 0; i < n; i += VL) { int vl = min(VL, n - i); for (int j = 0; j < vl; ++j) a[j] = b[j] + c[j]; a += vl; b += vl; c += vl; } } Then replace the innermost loop with intrinsic functions and __vr (vector register) type variables after including velintrin.h . #include <velintrin.h> #define VL 256 void vadd(double* a, double const* b, double const* c, int n) { for (int i = 0; i < n; i += VL) { int vl = min(VL, n - i); __vr vb = _vel_vld_vssl(8, b, vl); // load b to vb __vr vc = _vel_vld_vssl(8, c, vl); // load c to vc __vr va = _vel_vfaddd_vvvl(vb, bc, vl); // va = vb + vc _vel_vst_vssl(va, 8, a, vl); // store va to a a += vl; b += vl; c += vl; } } A vector register can hold 256 64bit elements and an intrinsic function operates vl elements in it. vl is passed as a last argument of an intrinsic function. The four intrinsics used in this example are compiled to four vector instructions vld, vld, vfadd.d, vst . This is an important benefit of intrinsics. You can use the instructions you want to use. Other examples can be found: https://github.com/sx-aurora-dev/vetfkernel/tree/master/vml/src/intrinsic https://github.com/sx-aurora-dev/vednn","title":"Introduction: Implementing VectorAdd"},{"location":"optimization/","text":"Optimization Hints Here is some topics about perforamnce optimization. nc variants of memory access intrinsics Memor access intrinsics such as vector load, store, gather and scatter, have variants that has nc in mnemonic such as _vel_vldnc_vssl . It can be used to minimize polution of LLC, Last Level Cache. See ISA Guide for details. other topics... scheduling: load/store and arithmetic svob, ot unrolling approximate low throghput, cross-pipe instructions","title":"Optimization Hints"},{"location":"optimization/#optimization-hints","text":"Here is some topics about perforamnce optimization.","title":"Optimization Hints"},{"location":"optimization/#nc-variants-of-memory-access-intrinsics","text":"Memor access intrinsics such as vector load, store, gather and scatter, have variants that has nc in mnemonic such as _vel_vldnc_vssl . It can be used to minimize polution of LLC, Last Level Cache. See ISA Guide for details. other topics... scheduling: load/store and arithmetic svob, ot unrolling approximate low throghput, cross-pipe instructions","title":"nc variants of memory access intrinsics"},{"location":"references/","text":"References VE Intrinsics Complete list of VE Intrinscs ISA Assembly manual SX-Aurora TSUBASA Architecture Guide(ISA Guide) Processor archicture Vector Engine Processor of NEC\u2019s Brand-New Supercomputer SX-Aurora TSUBASA (HotChips 2018) Others LLVM-VE releases NEC Aurora Forum","title":"References"},{"location":"references/#references","text":"VE Intrinsics Complete list of VE Intrinscs ISA Assembly manual SX-Aurora TSUBASA Architecture Guide(ISA Guide) Processor archicture Vector Engine Processor of NEC\u2019s Brand-New Supercomputer SX-Aurora TSUBASA (HotChips 2018) Others LLVM-VE releases NEC Aurora Forum","title":"References"},{"location":"setup/","text":"Getting started: Setup LLVM-VE LLVM-VE is a community supported open source compiler and not included in the official SDK for SX-Aurora TSUBASA. First of all you have to install LLVM-VE. The LLVM-VE rpm packages are released at our branch of llvm. Note that the official llvm repository also has VE backend, but it does not yet support VE intrinsics at the time of writing. If you prefer a yum repository, see https://www.sx-aurora.com/repos/llvm/x86_64/ . Install LLVM-VE. % yum install llmv-ve-<version>.rpm llvm-ve-link-<version>.rpm LLVM-VE is installed into /opt/nec/nosupport/llvm-ve-<version> and latest version is linked from /opt/nec/nosupport/llvm-ve . The compiler can be invoked as below. % /opt/nec/nosupport/llvm-ve/clang -target ve-linux -O3 -c func.c Because current LLVM-VE does not support automatic vectorization, we recommend to use llvm-ve with ncc/nc++/nfort, default compilers for VE. You typically create the dedicated source files for llvm-ve that includes minimum code with intrinsics. Other source files should be compiled by ncc, then linked by ncc. For example, % /opt/nec/nosupport/llvm-ve/clang -target ve-linux -O3 -c intrinsics.c % /opt/nec/ve/bin/ncc -c main.c % /opt/nec/ve/bin/ncc -o a.out intrinsics.o main.o OpenMP LLVE-VE supports OpenMP but its runtime is different from ncc's runtime. We strongly recommend to use ncc's OpenMP. In other word, source code with intrinsics should not include OpenMP.","title":"Getting Started"},{"location":"setup/#getting-started-setup-llvm-ve","text":"LLVM-VE is a community supported open source compiler and not included in the official SDK for SX-Aurora TSUBASA. First of all you have to install LLVM-VE. The LLVM-VE rpm packages are released at our branch of llvm. Note that the official llvm repository also has VE backend, but it does not yet support VE intrinsics at the time of writing. If you prefer a yum repository, see https://www.sx-aurora.com/repos/llvm/x86_64/ . Install LLVM-VE. % yum install llmv-ve-<version>.rpm llvm-ve-link-<version>.rpm LLVM-VE is installed into /opt/nec/nosupport/llvm-ve-<version> and latest version is linked from /opt/nec/nosupport/llvm-ve . The compiler can be invoked as below. % /opt/nec/nosupport/llvm-ve/clang -target ve-linux -O3 -c func.c Because current LLVM-VE does not support automatic vectorization, we recommend to use llvm-ve with ncc/nc++/nfort, default compilers for VE. You typically create the dedicated source files for llvm-ve that includes minimum code with intrinsics. Other source files should be compiled by ncc, then linked by ncc. For example, % /opt/nec/nosupport/llvm-ve/clang -target ve-linux -O3 -c intrinsics.c % /opt/nec/ve/bin/ncc -c main.c % /opt/nec/ve/bin/ncc -o a.out intrinsics.o main.o","title":"Getting started: Setup LLVM-VE"},{"location":"setup/#openmp","text":"LLVE-VE supports OpenMP but its runtime is different from ncc's runtime. We strongly recommend to use ncc's OpenMP. In other word, source code with intrinsics should not include OpenMP.","title":"OpenMP"},{"location":"topics/","text":"Other Topics In this section, more topics will be described. Vector Load and Store The instrinsics you have to know first should be vector load and store to load/store regular data such as consecutive or constant stride data from/to memory. The intrinsic you need varies depending on your data type. To load 64bit data such as fp64(double) and int64, _vel_vld_vssl intrinsic can be used. To load 32bit data, there are two intrinsics because we have conventions to load fp32(float) into upper half of 64b, and to load int32 into lower half. To this end, load upper _vel_vldu_vssl and load lower _vel_vldl_vssl can be used. __vr v = _vel_vld_vssl(8, a, 256); // double* a or int64_t* a __vr v = _vel_vldu_vssl(4, a, 256); // float* a; __vr v = _vel_vldl_vssl(4, a, 256); // int32_t* a; Vector load and vector store have two scalar arguments. First one is a stride in byte and second one is a base address. When you load consecutive elements of fp64, a stride should be 8B. When fp32, it is 4B. In above example, all loads are consecutive loads. You can use longer stride to load non consecutive elements, such as loading a column in 2d matrix. double m[256*256]; // 256x256 row-major matrix __vr v0 = _vel_vld_vssl(8, m, 256); // load row: m[i] (i=0-255) __vr v1 = _vel_vld_vssl(8*256, m, 256); // load column: m[i*256] (i=0-255) __vr v2 = _vel_vsl_vssl(8*2, m+1, 256); // load odd elements: m[2*i+1] (i=0-255) Packed Instructions VE has packed instructions that operate 512 elements of fp32 or int32 in a vector register. In intrinsics, packed instruction has prefix p before instruction name. For example, _vel_pvfadd_vl is packed version of _vel_vfadds_vvvl ( s in vfadds that means fp32 is removed). You can load 512 32-bit elemens into a vector register by using a single VLD instruction (as 256 32-bit elements), but data should be 8e aligned. When a packed instruction takes a scalar value as an input operand, it also has to be packed, i.e. a 64-bit scalar consists of 32b upper and 32b lower part. VE intrinsics includes the functions to build a packed scalar. Hardware packed instructions can take two 256-bit vector mask register. VE intrinsics provide __vm512 type that is mapped to two hardware vector mask registers, and intrinsics for packed instructions accpet it ( M in a suffix). VE intrinsics also provide pseudo instructions for __vm512 variables such as __vm512 _vel_andm_MMM(__vm512 vmy, __vm512 vmz) . These pseudo instructions are compiled to two hardware instructions. You can extract __vm256 from __vm512 by using _vel_extract_vm512u and _vel_extract_vm512l . Also functions for inserting are provided.","title":"Other Topics"},{"location":"topics/#other-topics","text":"In this section, more topics will be described.","title":"Other Topics"},{"location":"topics/#vector-load-and-store","text":"The instrinsics you have to know first should be vector load and store to load/store regular data such as consecutive or constant stride data from/to memory. The intrinsic you need varies depending on your data type. To load 64bit data such as fp64(double) and int64, _vel_vld_vssl intrinsic can be used. To load 32bit data, there are two intrinsics because we have conventions to load fp32(float) into upper half of 64b, and to load int32 into lower half. To this end, load upper _vel_vldu_vssl and load lower _vel_vldl_vssl can be used. __vr v = _vel_vld_vssl(8, a, 256); // double* a or int64_t* a __vr v = _vel_vldu_vssl(4, a, 256); // float* a; __vr v = _vel_vldl_vssl(4, a, 256); // int32_t* a; Vector load and vector store have two scalar arguments. First one is a stride in byte and second one is a base address. When you load consecutive elements of fp64, a stride should be 8B. When fp32, it is 4B. In above example, all loads are consecutive loads. You can use longer stride to load non consecutive elements, such as loading a column in 2d matrix. double m[256*256]; // 256x256 row-major matrix __vr v0 = _vel_vld_vssl(8, m, 256); // load row: m[i] (i=0-255) __vr v1 = _vel_vld_vssl(8*256, m, 256); // load column: m[i*256] (i=0-255) __vr v2 = _vel_vsl_vssl(8*2, m+1, 256); // load odd elements: m[2*i+1] (i=0-255)","title":"Vector Load and Store"},{"location":"topics/#packed-instructions","text":"VE has packed instructions that operate 512 elements of fp32 or int32 in a vector register. In intrinsics, packed instruction has prefix p before instruction name. For example, _vel_pvfadd_vl is packed version of _vel_vfadds_vvvl ( s in vfadds that means fp32 is removed). You can load 512 32-bit elemens into a vector register by using a single VLD instruction (as 256 32-bit elements), but data should be 8e aligned. When a packed instruction takes a scalar value as an input operand, it also has to be packed, i.e. a 64-bit scalar consists of 32b upper and 32b lower part. VE intrinsics includes the functions to build a packed scalar. Hardware packed instructions can take two 256-bit vector mask register. VE intrinsics provide __vm512 type that is mapped to two hardware vector mask registers, and intrinsics for packed instructions accpet it ( M in a suffix). VE intrinsics also provide pseudo instructions for __vm512 variables such as __vm512 _vel_andm_MMM(__vm512 vmy, __vm512 vmz) . These pseudo instructions are compiled to two hardware instructions. You can extract __vm256 from __vm512 by using _vel_extract_vm512u and _vel_extract_vm512l . Also functions for inserting are provided.","title":"Packed Instructions"}]}